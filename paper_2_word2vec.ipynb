{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 603\n",
      "Number of unique queries: 596\n",
      "Query frequencies range:  [1, 4]\n",
      "Average query length: 21.432835820895523\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "# POT needs to be installed for the following code to work\n",
    "# !pip install POT\n",
    "\n",
    "df = pd.read_csv('data/children-with-query-frequencies-and-tokens.txt', sep='\\t')\n",
    "\n",
    "frequencies = pd.read_csv('data/children-query-frequencies-precomputed.txt', sep='\\t', index_col=0)\n",
    "tokens = pd.read_csv('data/children-query-tokens-precomputed.txt', sep='\\t', index_col=0)\n",
    "idf_scores = pd.read_csv('data/children-idf-scores-precomputed.txt', sep='\\t', index_col=0)\n",
    "\n",
    "# Dataset statistics\n",
    "print('Number of rows:', df.shape[0])\n",
    "# print('Number of unique users:', df['AnonID'].nunique())\n",
    "print('Number of unique queries:', df['Query'].nunique())\n",
    "print('Query frequencies range:  [{}, {}]'.format(df['QueryFrequency'].min(), df['QueryFrequency'].max()))\n",
    "print('Average query length:', df['Query'].apply(len).mean())\n",
    "\n",
    "# User 479 queries:\n",
    "# df[df['AnonID'] == 479]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 queries by frequency\n",
      "Query\n",
      "youtube                             4\n",
      "games                               3\n",
      "Star wars                           2\n",
      "weather                             2\n",
      "best walking shoes for babies       1\n",
      "best gps deals                      1\n",
      "best love novels                    1\n",
      "best professional digital camera    1\n",
      "best rc truck                       1\n",
      "best songs of the 80s and 90s       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Most frequent users and their query counts\n",
    "# print(\"Top 10 users by query count\")\n",
    "# print(df['AnonID'].value_counts().head(10))\n",
    "\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# Most frequent queries\n",
    "print(\"Top 10 queries by frequency\")\n",
    "print(df['Query'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 top completions for 'fast':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fast in the fouris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast food design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     \n",
       "0  fast in the fouris\n",
       "1    fast food design\n",
       "2            fast now"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query completion, based on the most frequent queries starting with the given query\n",
    "def query_completion(query):\n",
    "    starts_with_query = df['Query'].str.startswith(query)\n",
    "\n",
    "    return df[starts_with_query].sort_values('QueryFrequency', ascending=False)['Query'].unique()[:10]\n",
    "\n",
    "print(\"10 top completions for 'fast':\")\n",
    "pd.DataFrame(query_completion('fast'), columns=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Query Auto-Completion Based on Word2vec Semantic Similarity\n",
    "Considers semantic similarity between the candidate queries and their previous queries submitted in the same session, on the basis of word2vec method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building word2vec vocabulary: 100%|██████████| 603/603 [00:00<00:00, 302640.34it/s]\n",
      "Training word2vec model: 100%|██████████| 603/603 [00:00<00:00, 119996.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm  # Progress bar for training\n",
    "\n",
    "# Tokenize queries (with tqdm progress bar)\n",
    "queries = df['Query']\n",
    "query_tokens = df['QueryTokens']\n",
    "\n",
    "# Initialize word2vec model\n",
    "AOL_model = Word2Vec(vector_size=200,   # Dimension of the word vectors\n",
    "                 window=5,          # Context window size\n",
    "                 min_count=1,       # Minimum word frequency\n",
    "                 workers=4,         # Number of parallel workers\n",
    "                 sg=1)              # Skip-gram model\n",
    "\n",
    "# Train word2vec model\n",
    "AOL_model.build_vocab(tqdm(query_tokens, desc='Building word2vec vocabulary'))\n",
    "\n",
    "AOL_model.train(tqdm(query_tokens, desc='Training word2vec model'),\n",
    "            total_examples=AOL_model.corpus_count,\n",
    "            epochs=30)\n",
    "\n",
    "# Save word2vec model\n",
    "AOL_model.save('word2vec_AOL.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load Google's pre-trained Word2Vec model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# google_model = KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)  # if you have it locally\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m google_model \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword2vec-google-news-300\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the trained AOL word2vec model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# AOL_model = Word2Vec.load('models/word2vec_AOL.model')   # Only if you don't want to retrain it (but it's quite fast to train, ~15 min)\u001b[39;00m\n",
      "File \u001b[1;32md:\\UNI\\IR\\finalproj\\myenv\\Lib\\site-packages\\gensim\\downloader.py:503\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    501\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, BASE_DIR)\n\u001b[0;32m    502\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28m__import__\u001b[39m(name)\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~/gensim-data\\word2vec-google-news-300\\__init__.py:8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec-google-news-300.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\UNI\\IR\\finalproj\\myenv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UNI\\IR\\finalproj\\myenv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2062\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[0;32m   2061\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n\u001b[1;32m-> 2062\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n",
      "File \u001b[1;32md:\\UNI\\IR\\finalproj\\myenv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:245\u001b[0m, in \u001b[0;36mKeyedVectors.__init__\u001b[1;34m(self, vector_size, count, dtype, mapfile_path)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# pointer to where next new entry will land\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_to_index \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# formerly known as syn0\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# \"expandos\" are extra attributes stored for each key: {attribute_name} => numpy array of values of\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# this attribute, with one array value for each vector key.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# The same information used to be stored in a structure called Vocab in Gensim <4.0.0, but\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# with different indexing: {vector key} => Vocab object containing all attributes for the given vector key.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Don't modify expandos directly; call set_vecattr()/get_vecattr() instead.\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model\n",
    "# google_model = KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)  # if you have it locally\n",
    "google_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Load the trained AOL word2vec model\n",
    "# AOL_model = Word2Vec.load('models/word2vec_AOL.model')   # Only if you don't want to retrain it (but it's quite fast to train, ~15 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "# Query auto-completion function\n",
    "def query_completion(query, completion_list, session_queries, alpha=0.6):\n",
    "    N = len(session_queries)\n",
    "    gamma = beta = 1/(N+1)\n",
    "    omega = 0.5\n",
    "\n",
    "    # Frequency score (of each candidate query)\n",
    "    frequency_score = [frequencies.loc[a, 'Frequency'] if a in frequencies.index else 0 for a in completion_list]\n",
    "\n",
    "    # Semantic similarity score\n",
    "    # Use average similarity score on words (average of all word pairs)\n",
    "    similarity_score = []\n",
    "    for candidate_query in completion_list:  # Possible completions\n",
    "        candidate_score = 0\n",
    "\n",
    "        for session_query in session_queries:  # User session queries\n",
    "            google_model_score = 0\n",
    "            AOL_model_score = 0\n",
    "\n",
    "            c_tokens = word_tokenize(candidate_query)\n",
    "            x_tokens = word_tokenize(session_query)\n",
    "\n",
    "            # Add similarities of all word pairs between the candidate query and the session query,\n",
    "            # weighted by the idf of the words\n",
    "            for c in c_tokens:\n",
    "                for x in x_tokens:\n",
    "                    # Check if the words are in the models' vocabularies\n",
    "                    if c in google_model.key_to_index and x in google_model.key_to_index:\n",
    "                        google_model_similarity = google_model.similarity(c, x)\n",
    "                    else:\n",
    "                        google_model_similarity = 0\n",
    "                    if c in AOL_model.wv.key_to_index and x in AOL_model.wv.key_to_index:\n",
    "                        AOL_model_similarity = AOL_model.wv.similarity(c, x)\n",
    "                    else:\n",
    "                        AOL_model_similarity = 0\n",
    "\n",
    "                    # Idf weighting average:\n",
    "                    if c in idf_scores.index.values and x in idf_scores.index.values:\n",
    "                        # Idf scores (precomputed)\n",
    "                        c_idf = idf_scores.loc[idf_scores.index == c, 'IDF'].values[0]\n",
    "                        x_idf = idf_scores.loc[idf_scores.index == x, 'IDF'].values[0]\n",
    "\n",
    "                        google_model_score += (google_model_similarity * c_idf * x_idf)\n",
    "                        AOL_model_score += (AOL_model_similarity * c_idf * x_idf)\n",
    "                    else:\n",
    "                        google_model_score += google_model_similarity\n",
    "                        AOL_model_score += AOL_model_similarity\n",
    "\n",
    "            # Average, divide by all combinations of words:\n",
    "            google_model_score /= (len(c_tokens) * len(x_tokens))\n",
    "            AOL_model_score /= (len(c_tokens) * len(x_tokens))\n",
    "\n",
    "            # Some query words might not appear in the google model's vocabulary:\n",
    "            if google_model_score == 0:\n",
    "                candidate_score += AOL_model_score\n",
    "            else:\n",
    "                candidate_score += omega * AOL_model_score + (1 - omega) * google_model_score\n",
    "\n",
    "        similarity_score.append(candidate_score)\n",
    "\n",
    "    # Combined score (alpha * similarity_score + (1-alpha) * frequency_score)\n",
    "    combined_score = [alpha * similarity_score[i] + (1 - alpha) * frequency_score[i] for i in range(len(completion_list))]\n",
    "\n",
    "    # Re-rank completion list\n",
    "    re_ranked_list = [x for _, x in sorted(zip(combined_score, completion_list), reverse=True)]\n",
    "\n",
    "    return re_ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummy test the query auto-completion function\n",
    "# query = 'car'\n",
    "# completion_list = df[df['Query'].str.startswith(query)]['Query'].unique()  # Queries starting with 'car'\n",
    "# session_queries = df[(df['AnonID'] == 479) & (df['Query'].str.contains('car'))]['Query'].unique()  # Queries from user 479 containing 'car'\n",
    "# print(session_queries)\n",
    "\n",
    "# print(\"Query auto-completion for 'car':\")\n",
    "# print(query_completion(query, completion_list, session_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MRR (Mean Reciprocal Rank) evaluation\n",
    "def RR(ranked_completions, ground_truth):\n",
    "    \"\"\"\n",
    "    Reciprocal Rank (RR) for one query.\n",
    "    :param ranked_completions: list of suggested completions (higher rank first)\n",
    "    :param ground_truth: the correct suggestion of the query\n",
    "    :return: the RR score\n",
    "    \"\"\"\n",
    "    for i, completion in enumerate(ranked_completions):\n",
    "        if completion == ground_truth:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def MRR(completion_lists, ground_truths):\n",
    "    \"\"\"\n",
    "    Mean of scores for entire dataset.\n",
    "    \"\"\"\n",
    "    total_score = 0.0\n",
    "    for i, completion_list in enumerate(completion_lists):\n",
    "        total_score += RR(completion_list, ground_truths[i])\n",
    "\n",
    "    return total_score / len(completion_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  2709614 queries\n",
      "Test dataset size:  262547 sessions and 904763 queries\n",
      "First 10 sessions in test dataset: \n",
      "[['-', '-', '-', '-'], ['myspace.com'], ['pet sitter in newburyport ma', 'pet sitter in newburyport ma'], ['undefined'], ['shakira lyrics'], ['ebay', 'social security'], ['glutes', 'glutes', 'glutes', 'glutes', 'glutes', 'adultfriendfinder'], ['sandals vacations'], ['www.delta.com'], ['costco']]\n",
      "Session lengths in test dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      113402\n",
       "2       51078\n",
       "3       28311\n",
       "4       17455\n",
       "5       11957\n",
       "        ...  \n",
       "122         1\n",
       "138         1\n",
       "183         1\n",
       "162         1\n",
       "150         1\n",
       "Length: 141, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test datasets (arrays of query sessions, sorted by time increasing)\n",
    "with open('data/children-train.pkl', 'rb') as f:\n",
    "    train = pkl.load(f)\n",
    "\n",
    "with open('data/children-test.pkl', 'rb') as f:\n",
    "    test = pkl.load(f)\n",
    "\n",
    "# Flatten train dataset\n",
    "train = [query for session in train for query in session]\n",
    "train = pd.DataFrame(train, columns=['Query'])\n",
    "\n",
    "print(\"Train dataset size: \", len(train), \"queries\")\n",
    "print(\"Test dataset size: \", len(test), \"sessions and\", len([query for session in test for query in session]), \"queries\")\n",
    "print(\"First 10 sessions in test dataset: \")\n",
    "print(test[:10])\n",
    "# Session lengths counts\n",
    "print(\"Session lengths in test dataset: \")\n",
    "pd.Series([len(session) for session in test]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count of last session query in test dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     127437\n",
       "2      59492\n",
       "3      36285\n",
       "4      19425\n",
       "5       9875\n",
       "       ...  \n",
       "92         1\n",
       "33         1\n",
       "95         1\n",
       "49         1\n",
       "87         1\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Word count of last session query in test dataset: \")\n",
    "pd.Series([len(word_tokenize(session[-1])) for session in test]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_completions(sessions, prefix_length, train_df, alpha=0.6):\n",
    "    completion_lists = []\n",
    "    ground_truths = []\n",
    "\n",
    "    for session in tqdm(sessions, desc='Generating completions'):\n",
    "        # Last query in the session is the query we want to complete\n",
    "        query_ground_truth = session[-1]\n",
    "        query_tokenized = word_tokenize(query_ground_truth)\n",
    "\n",
    "        # Skip if the query is shorter than the prefix length\n",
    "        if len(query_tokenized) < prefix_length:\n",
    "            continue\n",
    "\n",
    "        # Queries preceding the last query in the session\n",
    "        previous_queries = session[:-1] if len(session) > 1 else []\n",
    "\n",
    "        # Get prefix (part of the query that needs to be completed)\n",
    "        query_prefix = ' '.join(query_tokenized[:prefix_length])\n",
    "\n",
    "        # Get completions\n",
    "        completions = train_df[train_df['Query'].str.startswith(query_prefix + \" \")]['Query'].unique() # here we add a space after the word so we don't look for partial matches\n",
    "\n",
    "        # Re-rank completions\n",
    "        ranked_completions = query_completion(query_prefix, completions, previous_queries, alpha)\n",
    "\n",
    "        completion_lists.append(ranked_completions)\n",
    "        ground_truths.append(query_ground_truth)\n",
    "\n",
    "    return completion_lists, ground_truths\n",
    "\n",
    "def evaluate_test_set(test, prefix_length, alpha=0.6):\n",
    "    completion_lists, ground_truths = get_completions(test, prefix_length, train, alpha)\n",
    "    mrr = MRR(completion_lists, ground_truths)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions:   0%|          | 341/262547 [00:25<5:31:38, 13.18it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the test set\u001b[39;00m\n\u001b[0;32m      2\u001b[0m prefix_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m   \u001b[38;5;66;03m# query will be completed based on the first 3 words\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m mrr \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_test_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMRR for prefix length\u001b[39m\u001b[38;5;124m\"\u001b[39m, prefix_length, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mrr)\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mevaluate_test_set\u001b[1;34m(test, prefix_length, alpha)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_test_set\u001b[39m(test, prefix_length, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m     completion_lists, ground_truths \u001b[38;5;241m=\u001b[39m \u001b[43mget_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     mrr \u001b[38;5;241m=\u001b[39m MRR(completion_lists, ground_truths)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mrr\n",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m, in \u001b[0;36mget_completions\u001b[1;34m(sessions, prefix_length, train_df, alpha)\u001b[0m\n\u001b[0;32m     21\u001b[0m completions \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(query_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;66;03m# here we add a space after the word so we don't look for partial matches\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Re-rank completions\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m ranked_completions \u001b[38;5;241m=\u001b[39m \u001b[43mquery_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_queries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m completion_lists\u001b[38;5;241m.\u001b[39mappend(ranked_completions)\n\u001b[0;32m     27\u001b[0m ground_truths\u001b[38;5;241m.\u001b[39mappend(query_ground_truth)\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mquery_completion\u001b[1;34m(query, completion_list, session_queries, alpha)\u001b[0m\n\u001b[0;32m     39\u001b[0m     AOL_model_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Idf weighting average:\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m idf_scores\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43midf_scores\u001b[49m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Idf scores (precomputed)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     c_idf \u001b[38;5;241m=\u001b[39m idf_scores\u001b[38;5;241m.\u001b[39mloc[idf_scores\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m==\u001b[39m c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m     x_idf \u001b[38;5;241m=\u001b[39m idf_scores\u001b[38;5;241m.\u001b[39mloc[idf_scores\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m==\u001b[39m x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 5   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 4   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions: 100%|██████████| 20/20 [01:15<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for prefix length 3 : 0.14285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 3   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 2   # query will be completed based on the first 2 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 1   # query will be completed based on the first word (VERY SLOW)\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
