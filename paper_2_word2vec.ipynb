{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3614377\n",
      "Number of unique users: 65999\n",
      "Number of unique queries: 1244495\n",
      "Query frequencies range:  [1, 98554]\n",
      "Average query length: 17.424875158291457\n"
     ]
    },
    {
     "data": {
      "text/plain": "     AnonID                            Query            QueryTime  ItemRank  \\\n0       479                       family guy  2006-03-01 16:01:20       NaN   \n1       479          also sprach zarathustra  2006-03-02 14:48:55       NaN   \n2       479      family guy movie references  2006-03-03 22:37:46       1.0   \n3       479  top grossing movies of all time  2006-03-03 22:42:42       1.0   \n4       479  top grossing movies of all time  2006-03-03 22:42:42       2.0   \n..      ...                              ...                  ...       ...   \n118     479                         nip tuck  2006-05-28 00:44:58       4.0   \n119     479                nip tuck season 4  2006-05-28 00:47:05       NaN   \n120     479            nip tuck season 3 dvd  2006-05-28 00:47:48       7.0   \n121     479            nip tuck season 3 dvd  2006-05-28 00:47:48       9.0   \n122     479            nip tuck season 3 dvd  2006-05-28 00:47:48       1.0   \n\n                          ClickURL  QueryFrequency  \\\n0                              NaN             191   \n1                              NaN               1   \n2    http://www.familyguyfiles.com               1   \n3              http://movieweb.com               2   \n4              http://www.imdb.com               2   \n..                             ...             ...   \n118         http://www.niptuck.com              24   \n119                            NaN               4   \n120        http://en.wikipedia.org               3   \n121      http://www.dvdtimes.co.uk               3   \n122        http://www.amazon.co.uk               3   \n\n                                           QueryTokens  \n0                                    ['family', 'guy']  \n1                    ['also', 'sprach', 'zarathustra']  \n2             ['family', 'guy', 'movie', 'references']  \n3    ['top', 'grossing', 'movies', 'of', 'all', 'ti...  \n4    ['top', 'grossing', 'movies', 'of', 'all', 'ti...  \n..                                                 ...  \n118                                    ['nip', 'tuck']  \n119                     ['nip', 'tuck', 'season', '4']  \n120              ['nip', 'tuck', 'season', '3', 'dvd']  \n121              ['nip', 'tuck', 'season', '3', 'dvd']  \n122              ['nip', 'tuck', 'season', '3', 'dvd']  \n\n[123 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AnonID</th>\n      <th>Query</th>\n      <th>QueryTime</th>\n      <th>ItemRank</th>\n      <th>ClickURL</th>\n      <th>QueryFrequency</th>\n      <th>QueryTokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>479</td>\n      <td>family guy</td>\n      <td>2006-03-01 16:01:20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>191</td>\n      <td>['family', 'guy']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>479</td>\n      <td>also sprach zarathustra</td>\n      <td>2006-03-02 14:48:55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>['also', 'sprach', 'zarathustra']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>479</td>\n      <td>family guy movie references</td>\n      <td>2006-03-03 22:37:46</td>\n      <td>1.0</td>\n      <td>http://www.familyguyfiles.com</td>\n      <td>1</td>\n      <td>['family', 'guy', 'movie', 'references']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>479</td>\n      <td>top grossing movies of all time</td>\n      <td>2006-03-03 22:42:42</td>\n      <td>1.0</td>\n      <td>http://movieweb.com</td>\n      <td>2</td>\n      <td>['top', 'grossing', 'movies', 'of', 'all', 'ti...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>479</td>\n      <td>top grossing movies of all time</td>\n      <td>2006-03-03 22:42:42</td>\n      <td>2.0</td>\n      <td>http://www.imdb.com</td>\n      <td>2</td>\n      <td>['top', 'grossing', 'movies', 'of', 'all', 'ti...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>479</td>\n      <td>nip tuck</td>\n      <td>2006-05-28 00:44:58</td>\n      <td>4.0</td>\n      <td>http://www.niptuck.com</td>\n      <td>24</td>\n      <td>['nip', 'tuck']</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>479</td>\n      <td>nip tuck season 4</td>\n      <td>2006-05-28 00:47:05</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>['nip', 'tuck', 'season', '4']</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>479</td>\n      <td>nip tuck season 3 dvd</td>\n      <td>2006-05-28 00:47:48</td>\n      <td>7.0</td>\n      <td>http://en.wikipedia.org</td>\n      <td>3</td>\n      <td>['nip', 'tuck', 'season', '3', 'dvd']</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>479</td>\n      <td>nip tuck season 3 dvd</td>\n      <td>2006-05-28 00:47:48</td>\n      <td>9.0</td>\n      <td>http://www.dvdtimes.co.uk</td>\n      <td>3</td>\n      <td>['nip', 'tuck', 'season', '3', 'dvd']</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>479</td>\n      <td>nip tuck season 3 dvd</td>\n      <td>2006-05-28 00:47:48</td>\n      <td>1.0</td>\n      <td>http://www.amazon.co.uk</td>\n      <td>3</td>\n      <td>['nip', 'tuck', 'season', '3', 'dvd']</td>\n    </tr>\n  </tbody>\n</table>\n<p>123 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "# POT needs to be installed for the following code to work\n",
    "# !pip install POT\n",
    "\n",
    "df = pd.read_csv('data/user-ct-test-collection-02-with-query-frequencies-and-tokens.txt', sep='\\t')\n",
    "\n",
    "frequencies = pd.read_csv('data/query-frequencies-precomputed.txt', sep='\\t', index_col=0)\n",
    "tokens = pd.read_csv('data/query-tokens-precomputed.txt', sep='\\t', index_col=0)\n",
    "idf_scores = pd.read_csv('data/idf-scores-precomputed.txt', sep='\\t', index_col=0)\n",
    "\n",
    "# Dataset statistics\n",
    "print('Number of rows:', df.shape[0])\n",
    "print('Number of unique users:', df['AnonID'].nunique())\n",
    "print('Number of unique queries:', df['Query'].nunique())\n",
    "print('Query frequencies range:  [{}, {}]'.format(df['QueryFrequency'].min(), df['QueryFrequency'].max()))\n",
    "print('Average query length:', df['Query'].apply(len).mean())\n",
    "\n",
    "# User 479 queries:\n",
    "df[df['AnonID'] == 479]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 users by query count\n",
      "3318459    6925\n",
      "205414     4663\n",
      "422471     4198\n",
      "2426641    4106\n",
      "3717968    3429\n",
      "3134676    3199\n",
      "1611540    2715\n",
      "901695     2651\n",
      "2037028    2520\n",
      "2067984    2294\n",
      "Name: AnonID, dtype: int64\n",
      "--------------------------------------------------\n",
      "Top 10 queries by frequency\n",
      "-                 98554\n",
      "google            32396\n",
      "yahoo             13344\n",
      "ebay              12949\n",
      "yahoo.com          8733\n",
      "mapquest           8680\n",
      "google.com         8139\n",
      "myspace            7653\n",
      "myspace.com        7099\n",
      "www.google.com     4255\n",
      "Name: Query, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Most frequent users and their query counts\n",
    "print(\"Top 10 users by query count\")\n",
    "print(df['AnonID'].value_counts().head(10))\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Most frequent queries\n",
    "print(\"Top 10 queries by frequency\")\n",
    "print(df['Query'].value_counts().head(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 top completions for 'weather':\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       \n0               weather\n1           weather.com\n2       weather channel\n3    weatherchannel.com\n4      weather forecast\n5           weather bug\n6            weatherbug\n7  weather in lattimore\n8   weather channel.com\n9         weather facts",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>weather</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>weather.com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>weather channel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>weatherchannel.com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>weather forecast</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>weather bug</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>weatherbug</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>weather in lattimore</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>weather channel.com</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>weather facts</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query completion, based on the most frequent queries starting with the given query\n",
    "def query_completion(query):\n",
    "    starts_with_query = df['Query'].str.startswith(query)\n",
    "\n",
    "    return df[starts_with_query].sort_values('QueryFrequency', ascending=False)['Query'].unique()[:10]\n",
    "\n",
    "print(\"10 top completions for 'weather':\")\n",
    "pd.DataFrame(query_completion('weather'), columns=[''])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query Auto-Completion Based on Word2vec Semantic Similarity\n",
    "Considers semantic similarity between the candidate queries and their previous queries submitted in the same session, on the basis of word2vec method.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm  # Progress bar for training\n",
    "\n",
    "# Tokenize queries (with tqdm progress bar)\n",
    "queries = df['Query']\n",
    "query_tokens = df['QueryTokens']\n",
    "\n",
    "# Initialize word2vec model\n",
    "AOL_model = Word2Vec(vector_size=200,   # Dimension of the word vectors\n",
    "                 window=5,          # Context window size\n",
    "                 min_count=1,       # Minimum word frequency\n",
    "                 workers=4,         # Number of parallel workers\n",
    "                 sg=1)              # Skip-gram model\n",
    "\n",
    "# Train word2vec model\n",
    "AOL_model.build_vocab(tqdm(query_tokens, desc='Building word2vec vocabulary'))\n",
    "\n",
    "AOL_model.train(tqdm(query_tokens, desc='Training word2vec model'),\n",
    "            total_examples=AOL_model.corpus_count,\n",
    "            epochs=30)\n",
    "\n",
    "# Save word2vec model\n",
    "AOL_model.save('word2vec_AOL.model')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model\n",
    "# google_model = KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)  # if you have it locally\n",
    "google_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Load the trained AOL word2vec model\n",
    "# AOL_model = Word2Vec.load('models/word2vec_AOL.model')   # Only if you don't want to retrain it (but it's quite fast to train, ~15 min)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "# Query auto-completion function\n",
    "def query_completion(query, completion_list, session_queries, alpha=0.6):\n",
    "    N = len(session_queries)\n",
    "    gamma = beta = 1/(N+1)\n",
    "    omega = 0.5\n",
    "\n",
    "    # Frequency score (of each candidate query)\n",
    "    frequency_score = [frequencies.loc[a, 'Frequency'] if a in frequencies.index else 0 for a in completion_list]\n",
    "\n",
    "    # Semantic similarity score\n",
    "    # Use average similarity score on words (average of all word pairs)\n",
    "    similarity_score = []\n",
    "    for candidate_query in completion_list:  # Possible completions\n",
    "        candidate_score = 0\n",
    "\n",
    "        for session_query in session_queries:  # User session queries\n",
    "            google_model_score = 0\n",
    "            AOL_model_score = 0\n",
    "\n",
    "            c_tokens = word_tokenize(candidate_query)\n",
    "            x_tokens = word_tokenize(session_query)\n",
    "\n",
    "            # Add similarities of all word pairs between the candidate query and the session query,\n",
    "            # weighted by the idf of the words\n",
    "            for c in c_tokens:\n",
    "                for x in x_tokens:\n",
    "                    # Check if the words are in the models' vocabularies\n",
    "                    if c in google_model.key_to_index and x in google_model.key_to_index:\n",
    "                        google_model_similarity = google_model.similarity(c, x)\n",
    "                    else:\n",
    "                        google_model_similarity = 0\n",
    "                    if c in AOL_model.wv.key_to_index and x in AOL_model.wv.key_to_index:\n",
    "                        AOL_model_similarity = AOL_model.wv.similarity(c, x)\n",
    "                    else:\n",
    "                        AOL_model_similarity = 0\n",
    "\n",
    "                    # Idf weighting average:\n",
    "                    if c in idf_scores.index.values and x in idf_scores.index.values:\n",
    "                        # Idf scores (precomputed)\n",
    "                        c_idf = idf_scores.loc[idf_scores.index == c, 'IDF'].values[0]\n",
    "                        x_idf = idf_scores.loc[idf_scores.index == x, 'IDF'].values[0]\n",
    "\n",
    "                        google_model_score += (google_model_similarity * c_idf * x_idf)\n",
    "                        AOL_model_score += (AOL_model_similarity * c_idf * x_idf)\n",
    "                    else:\n",
    "                        google_model_score += google_model_similarity\n",
    "                        AOL_model_score += AOL_model_similarity\n",
    "\n",
    "            # Average, divide by all combinations of words:\n",
    "            google_model_score /= (len(c_tokens) * len(x_tokens))\n",
    "            AOL_model_score /= (len(c_tokens) * len(x_tokens))\n",
    "\n",
    "            # Some query words might not appear in the google model's vocabulary:\n",
    "            if google_model_score == 0:\n",
    "                candidate_score += AOL_model_score\n",
    "            else:\n",
    "                candidate_score += omega * AOL_model_score + (1 - omega) * google_model_score\n",
    "\n",
    "        similarity_score.append(candidate_score)\n",
    "\n",
    "    # Combined score (alpha * similarity_score + (1-alpha) * frequency_score)\n",
    "    combined_score = [alpha * similarity_score[i] + (1 - alpha) * frequency_score[i] for i in range(len(completion_list))]\n",
    "\n",
    "    # Re-rank completion list\n",
    "    re_ranked_list = [x for _, x in sorted(zip(combined_score, completion_list), reverse=True)]\n",
    "\n",
    "    return re_ranked_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dummy test the query auto-completion function\n",
    "query = 'car'\n",
    "completion_list = df[df['Query'].str.startswith(query)]['Query'].unique()  # Queries starting with 'car'\n",
    "session_queries = df[(df['AnonID'] == 479) & (df['Query'].str.contains('car'))]['Query'].unique()  # Queries from user 479 containing 'car'\n",
    "print(session_queries)\n",
    "\n",
    "print(\"Query auto-completion for 'car':\")\n",
    "print(query_completion(query, completion_list, session_queries))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# MRR (Mean Reciprocal Rank) evaluation\n",
    "def RR(ranked_completions, ground_truth):\n",
    "    \"\"\"\n",
    "    Reciprocal Rank (RR) for one query.\n",
    "    :param ranked_completions: list of suggested completions (higher rank first)\n",
    "    :param ground_truth: the correct suggestion of the query\n",
    "    :return: the RR score\n",
    "    \"\"\"\n",
    "    for i, completion in enumerate(ranked_completions):\n",
    "        if completion == ground_truth:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def MRR(completion_lists, ground_truths):\n",
    "    \"\"\"\n",
    "    Mean of scores for entire dataset.\n",
    "    \"\"\"\n",
    "    total_score = 0.0\n",
    "    for i, completion_list in enumerate(completion_lists):\n",
    "        total_score += RR(completion_list, ground_truths[i])\n",
    "\n",
    "    return total_score / len(completion_lists)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  2709614 queries\n",
      "Test dataset size:  262547 sessions and 904763 queries\n",
      "First 10 sessions in test dataset: \n",
      "[['-', '-', '-', '-'], ['myspace.com'], ['pet sitter in newburyport ma', 'pet sitter in newburyport ma'], ['undefined'], ['shakira lyrics'], ['ebay', 'social security'], ['glutes', 'glutes', 'glutes', 'glutes', 'glutes', 'adultfriendfinder'], ['sandals vacations'], ['www.delta.com'], ['costco']]\n",
      "Session lengths in test dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": "1      113402\n2       51078\n3       28311\n4       17455\n5       11957\n        ...  \n122         1\n138         1\n183         1\n162         1\n150         1\nLength: 141, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test datasets (arrays of query sessions, sorted by time increasing)\n",
    "with open('data/train.pkl', 'rb') as f:\n",
    "    train = pkl.load(f)\n",
    "\n",
    "with open('data/test.pkl', 'rb') as f:\n",
    "    test = pkl.load(f)\n",
    "\n",
    "# Flatten train dataset\n",
    "train = [query for session in train for query in session]\n",
    "train = pd.DataFrame(train, columns=['Query'])\n",
    "\n",
    "print(\"Train dataset size: \", len(train), \"queries\")\n",
    "print(\"Test dataset size: \", len(test), \"sessions and\", len([query for session in test for query in session]), \"queries\")\n",
    "print(\"First 10 sessions in test dataset: \")\n",
    "print(test[:10])\n",
    "# Session lengths counts\n",
    "print(\"Session lengths in test dataset: \")\n",
    "pd.Series([len(session) for session in test]).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count of last session query in test dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": "1     127437\n2      59492\n3      36285\n4      19425\n5       9875\n       ...  \n92         1\n33         1\n95         1\n49         1\n87         1\nLength: 76, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Word count of last session query in test dataset: \")\n",
    "pd.Series([len(word_tokenize(session[-1])) for session in test]).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_completions(sessions, prefix_length, train_df, alpha=0.6):\n",
    "    completion_lists = []\n",
    "    ground_truths = []\n",
    "\n",
    "    for session in tqdm(sessions, desc='Generating completions'):\n",
    "        # Last query in the session is the query we want to complete\n",
    "        query_ground_truth = session[-1]\n",
    "        query_tokenized = word_tokenize(query_ground_truth)\n",
    "\n",
    "        # Skip if the query is shorter than the prefix length\n",
    "        if len(query_tokenized) < prefix_length:\n",
    "            continue\n",
    "\n",
    "        # Queries preceding the last query in the session\n",
    "        previous_queries = session[:-1] if len(session) > 1 else []\n",
    "\n",
    "        # Get prefix (part of the query that needs to be completed)\n",
    "        query_prefix = ' '.join(query_tokenized[:prefix_length])\n",
    "\n",
    "        # Get completions\n",
    "        completions = train_df[train_df['Query'].str.startswith(query_prefix + \" \")]['Query'].unique() # here we add a space after the word so we don't look for partial matches\n",
    "\n",
    "        # Re-rank completions\n",
    "        ranked_completions = query_completion(query_prefix, completions, previous_queries, alpha)\n",
    "\n",
    "        completion_lists.append(ranked_completions)\n",
    "        ground_truths.append(query_ground_truth)\n",
    "\n",
    "    return completion_lists, ground_truths\n",
    "\n",
    "def evaluate_test_set(test, prefix_length, alpha=0.6):\n",
    "    completion_lists, ground_truths = get_completions(test, prefix_length, train, alpha)\n",
    "    mrr = MRR(completion_lists, ground_truths)\n",
    "    return mrr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions:   0%|          | 341/262547 [00:25<5:31:38, 13.18it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Evaluate the test set\u001B[39;00m\n\u001B[0;32m      2\u001B[0m prefix_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m   \u001B[38;5;66;03m# query will be completed based on the first 3 words\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m mrr \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_test_set\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMRR for prefix length\u001B[39m\u001B[38;5;124m\"\u001B[39m, prefix_length, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m, mrr)\n",
      "Cell \u001B[1;32mIn[10], line 32\u001B[0m, in \u001B[0;36mevaluate_test_set\u001B[1;34m(test, prefix_length, alpha)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate_test_set\u001B[39m(test, prefix_length, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.6\u001B[39m):\n\u001B[1;32m---> 32\u001B[0m     completion_lists, ground_truths \u001B[38;5;241m=\u001B[39m \u001B[43mget_completions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefix_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m     mrr \u001B[38;5;241m=\u001B[39m MRR(completion_lists, ground_truths)\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mrr\n",
      "Cell \u001B[1;32mIn[10], line 24\u001B[0m, in \u001B[0;36mget_completions\u001B[1;34m(sessions, prefix_length, train_df, alpha)\u001B[0m\n\u001B[0;32m     21\u001B[0m completions \u001B[38;5;241m=\u001B[39m train_df[train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQuery\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mstartswith(query_prefix \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQuery\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique() \u001B[38;5;66;03m# here we add a space after the word so we don't look for partial matches\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# Re-rank completions\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m ranked_completions \u001B[38;5;241m=\u001B[39m \u001B[43mquery_completion\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_prefix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompletions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprevious_queries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m completion_lists\u001B[38;5;241m.\u001B[39mappend(ranked_completions)\n\u001B[0;32m     27\u001B[0m ground_truths\u001B[38;5;241m.\u001B[39mappend(query_ground_truth)\n",
      "Cell \u001B[1;32mIn[6], line 42\u001B[0m, in \u001B[0;36mquery_completion\u001B[1;34m(query, completion_list, session_queries, alpha)\u001B[0m\n\u001B[0;32m     39\u001B[0m     AOL_model_similarity \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Idf weighting average:\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m idf_scores\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;129;01mand\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[43midf_scores\u001B[49m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mvalues:\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;66;03m# Idf scores (precomputed)\u001B[39;00m\n\u001B[0;32m     44\u001B[0m     c_idf \u001B[38;5;241m=\u001B[39m idf_scores\u001B[38;5;241m.\u001B[39mloc[idf_scores\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m==\u001B[39m c, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIDF\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     45\u001B[0m     x_idf \u001B[38;5;241m=\u001B[39m idf_scores\u001B[38;5;241m.\u001B[39mloc[idf_scores\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m==\u001B[39m x, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIDF\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 5   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 4   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions: 100%|██████████| 20/20 [01:15<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for prefix length 3 : 0.14285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 3   # query will be completed based on the first 3 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 2   # query will be completed based on the first 2 words\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the test set\n",
    "prefix_length = 1   # query will be completed based on the first word (VERY SLOW)\n",
    "mrr = evaluate_test_set(test, prefix_length)\n",
    "print(\"MRR for prefix length\", prefix_length, \":\", mrr)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
